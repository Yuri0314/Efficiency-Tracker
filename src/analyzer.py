"""
AI Analysis Module.

This module handles building prompts and calling AI APIs to generate
efficiency analysis reports from processed ActivityWatch data.
"""

from __future__ import annotations

import os
from datetime import datetime
from typing import Any

import requests


class AIAnalyzer:
    """
    AI-powered analyzer for generating efficiency reports.

    This class builds prompts from processed statistics and calls an
    OpenAI-compatible API to generate natural language analysis.

    Attributes:
        api_base: The base URL of the AI API.
        api_key: The API key for authentication.
        model: The model identifier to use.
        max_tokens: Maximum tokens in the response.
        temperature: Sampling temperature for generation.

    Example:
        >>> analyzer = AIAnalyzer(
        ...     api_base="https://api.example.com/v1",
        ...     api_key="your-key",
        ...     model="gpt-4"
        ... )
        >>> prompt, summary = analyzer.build_prompt(stats, start, end, "Weekly")
        >>> report = analyzer.analyze(prompt)
    """

    def __init__(
        self,
        api_base: str,
        api_key: str,
        model: str = "glm-4.7",
        max_tokens: int = 2000,
        temperature: float = 0.7,
    ) -> None:
        """
        Initialize the AI analyzer.

        Environment variables OPENAI_BASE_URL and OPENAI_API_KEY take
        precedence over the provided arguments.

        Args:
            api_base: The base URL of the AI API.
            api_key: The API key for authentication.
            model: The model identifier to use. Defaults to "glm-4.7".
            max_tokens: Maximum tokens in the response. Defaults to 2000.
            temperature: Sampling temperature. Defaults to 0.7.
        """
        self.api_base = os.getenv("OPENAI_BASE_URL", api_base)
        self.api_key = os.getenv("OPENAI_API_KEY", api_key)
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature

    def build_prompt(
        self,
        stats: dict[str, Any],
        start: datetime,
        end: datetime,
        period_name: str,
    ) -> tuple[str, str]:
        """
        Build an AI analysis prompt from processed statistics.

        Args:
            stats: Processed statistics dictionary from DataProcessor.
            start: Start datetime of the report period.
            end: End datetime of the report period.
            period_name: Human-readable name for the period (e.g., "Weekly").

        Returns:
            A tuple of (prompt, data_summary) where:
                - prompt: The full prompt to send to the AI
                - data_summary: The formatted data summary for the report
        """
        period = f"{start.strftime('%Y-%m-%d')} ~ {end.strftime('%Y-%m-%d')}"

        app_list = "\n".join(
            [f"  - {app}: {hours}h" for app, hours in stats["by_app"]]
        )
        category_list = "\n".join(
            [f"  - {cat}: {hours}h" for cat, hours in stats["by_category"]]
        )

        # Browser statistics section
        browser_section = ""
        if stats["browser"]["top_domains"]:
            domain_list = "\n".join(
                [f"  - {d}: {h}h" for d, h in stats["browser"]["top_domains"][:5]]
            )
            browser_section = f"""
## æµè§ˆå™¨ä½¿ç”¨ï¼ˆå…± {stats['browser']['total_hours']}hï¼‰
{domain_list}
"""

        # Editor statistics section
        editor_section = ""
        if stats["editor"]["by_language"]:
            lang_list = "\n".join(
                [f"  - {lang}: {h}h" for lang, h in stats["editor"]["by_language"]]
            )
            proj_list = "\n".join(
                [f"  - {proj}: {h}h" for proj, h in stats["editor"]["by_project"][:3]]
            )
            editor_section = f"""
## ç¼–ç¨‹ç»Ÿè®¡ï¼ˆå…± {stats['editor']['total_hours']}hï¼‰
æŒ‰è¯­è¨€:
{lang_list}

æŒ‰é¡¹ç›®:
{proj_list}
"""

        data_summary = f"""
## æŠ¥å‘Šç±»å‹
{period_name}

## æ—¶é—´èŒƒå›´
{period}

## æ¦‚è§ˆ
- æ€»è®°å½•æ—¶é•¿: {stats['total_hours']} å°æ—¶
- æ´»è·ƒæ—¶é•¿ï¼ˆéAFKï¼‰: {stats['not_afk_hours']} å°æ—¶

## åº”ç”¨ä½¿ç”¨ TOP 10
{app_list}

## æŒ‰ç±»åˆ«ç»Ÿè®¡
{category_list}
{browser_section}
{editor_section}
"""

        # Calculate activity rate
        activity_rate = (
            round(stats["not_afk_hours"] / stats["total_hours"] * 100, 1)
            if stats["total_hours"] > 0
            else 0
        )

        prompt = f"""ä»¥ä¸‹æ˜¯æˆ‘{period_name}çš„ç”µè„‘ä½¿ç”¨æ•°æ®ç»Ÿè®¡ï¼š

{data_summary}

è¡¥å……ä¿¡æ¯ï¼š
- æ´»è·ƒç‡ï¼š{activity_rate}%ï¼ˆæ´»è·ƒæ—¶é•¿/æ€»è®°å½•æ—¶é•¿ï¼‰

è¯·åˆ†æè¿™äº›æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ç®€æ´çš„æ•ˆç‡æŠ¥å‘Šã€‚

## è¾“å‡ºæ ¼å¼

### ğŸ“Š æ•´ä½“æ¦‚è§ˆ
ï¼ˆç”¨1-2å¥è¯æ€»ç»“æœ¬å‘¨æœŸçš„æ•ˆç‡è¡¨ç°ï¼ŒåŒ…å«æ´»è·ƒç‡è¯„ä»·ï¼‰

### â° æ—¶é—´åˆ†é…
ï¼ˆåˆ†ææ—¶é—´ä¸»è¦èŠ±åœ¨å“ªäº›åº”ç”¨/ç±»åˆ«ï¼ŒæŒ‡å‡ºå æ¯”æœ€é«˜çš„2-3é¡¹ï¼‰

### ğŸ’¡ å‘ç°ä¸æ´å¯Ÿ
ï¼ˆåŸºäºæ•°æ®å‘ç°çš„æ¨¡å¼ã€è¶‹åŠ¿æˆ–æ½œåœ¨é—®é¢˜ï¼Œç”¨è¦ç‚¹åˆ—å‡ºï¼‰

### âœ… æ”¹è¿›å»ºè®®
ï¼ˆ1-2æ¡å…·ä½“å¯è¡Œçš„å»ºè®®ï¼Œé’ˆå¯¹å‘ç°çš„é—®é¢˜ï¼‰

æ³¨æ„ï¼šä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ é¢å¤–ç« èŠ‚ã€‚
"""
        return prompt, data_summary

    def analyze(self, prompt: str) -> str:
        """
        Call the AI API to analyze the data and generate a report.

        Args:
            prompt: The analysis prompt to send to the AI.

        Returns:
            The AI-generated analysis report, or an error message if the
            API call fails.
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸ªäººæ•ˆç‡åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„ç”µè„‘ä½¿ç”¨æ•°æ®ï¼Œ"
                        "æä¾›å®¢è§‚ã€æœ‰æ´å¯ŸåŠ›çš„æ•ˆç‡æŠ¥å‘Šã€‚\n\n"
                        "è¦æ±‚ï¼š\n"
                        "- åŸºäºæ•°æ®è¯´è¯ï¼Œä¸è¦ç¼–é€ æˆ–å‡è®¾ä¸å­˜åœ¨çš„ä¿¡æ¯\n"
                        "- è¯­æ°”å‹å¥½ä½†ä¸“ä¸šï¼Œåƒä¸€ä½å…³å¿ƒç”¨æˆ·çš„æ•ˆç‡æ•™ç»ƒ\n"
                        "- å»ºè®®è¦å…·ä½“å¯è¡Œï¼Œä¸è¦æ³›æ³›è€Œè°ˆ\n"
                        "- ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡ºï¼Œç»“æ„æ¸…æ™°"
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
        }

        try:
            resp = requests.post(
                f"{self.api_base}/chat/completions",
                headers=headers,
                json=payload,
                timeout=120,
            )
            resp.raise_for_status()
            result = resp.json()
            return result["choices"][0]["message"]["content"]
        except requests.exceptions.Timeout:
            return "AI è°ƒç”¨è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        except requests.exceptions.RequestException as e:
            return f"AI è°ƒç”¨å¤±è´¥: {e}"
        except (KeyError, IndexError) as e:
            return f"AI å“åº”è§£æå¤±è´¥: {e}"
