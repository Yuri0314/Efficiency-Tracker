"""
AI Analysis Module.

This module handles building prompts and calling AI APIs to generate
efficiency analysis reports from processed ActivityWatch data.
"""

from __future__ import annotations

import os
from datetime import datetime
from typing import Any

import requests


class AIAnalyzer:
    """
    AI-powered analyzer for generating efficiency reports.

    This class builds prompts from processed statistics and calls an
    OpenAI-compatible API to generate natural language analysis.

    Attributes:
        api_base: The base URL of the AI API.
        api_key: The API key for authentication.
        model: The model identifier to use.
        max_tokens: Maximum tokens in the response.
        temperature: Sampling temperature for generation.

    Example:
        >>> analyzer = AIAnalyzer(
        ...     api_base="https://api.example.com/v1",
        ...     api_key="your-key",
        ...     model="gpt-4"
        ... )
        >>> prompt, summary = analyzer.build_prompt(stats, start, end, "Weekly")
        >>> report = analyzer.analyze(prompt)
    """

    def __init__(
        self,
        api_base: str,
        api_key: str,
        model: str = "glm-4.7",
        max_tokens: int = 2000,
        temperature: float = 0.7,
    ) -> None:
        """
        Initialize the AI analyzer.

        Environment variables OPENAI_BASE_URL and OPENAI_API_KEY take
        precedence over the provided arguments.

        Args:
            api_base: The base URL of the AI API.
            api_key: The API key for authentication.
            model: The model identifier to use. Defaults to "glm-4.7".
            max_tokens: Maximum tokens in the response. Defaults to 2000.
            temperature: Sampling temperature. Defaults to 0.7.
        """
        self.api_base = os.getenv("OPENAI_BASE_URL", api_base)
        self.api_key = os.getenv("OPENAI_API_KEY", api_key)
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature

    def build_prompt(
        self,
        stats: dict[str, Any],
        start: datetime,
        end: datetime,
        period_name: str,
        trend_info: str | None = None,
    ) -> tuple[str, str]:
        """
        Build an AI analysis prompt from processed statistics and behavior views.

        Args:
            stats: Processed statistics dictionary from DataProcessor,
                including 'views' with timeline, sessions, hourly_switches,
                and website_summary.
            start: Start datetime of the report period.
            end: End datetime of the report period.
            period_name: Human-readable name for the period (e.g., "Weekly").
            trend_info: Optional formatted string with trend comparison data.

        Returns:
            A tuple of (prompt, data_summary) where:
                - prompt: The full prompt to send to the AI
                - data_summary: The formatted data summary for the report
        """
        period = f"{start.strftime('%Y-%m-%d')} ~ {end.strftime('%Y-%m-%d')}"

        # Basic statistics for reference
        app_list = "\n".join(
            [f"  - {app}: {hours}h" for app, hours in stats["by_app"]]
        )
        category_list = "\n".join(
            [f"  - {cat}: {hours}h" for cat, hours in stats["by_category"]]
        )

        # Editor statistics section
        editor_section = ""
        if stats["editor"]["by_language"]:
            lang_list = "\n".join(
                [f"  - {lang}: {h}h" for lang, h in stats["editor"]["by_language"]]
            )
            proj_list = "\n".join(
                [f"  - {proj}: {h}h" for proj, h in stats["editor"]["by_project"][:3]]
            )
            editor_section = f"""
## ç¼–ç¨‹ç»Ÿè®¡ï¼ˆå…± {stats['editor']['total_hours']}hï¼‰
æŒ‰è¯­è¨€:
{lang_list}

æŒ‰é¡¹ç›®:
{proj_list}
"""

        # Data summary for report (kept for backward compatibility)
        data_summary = f"""
## æŠ¥å‘Šç±»å‹
{period_name}

## æ—¶é—´èŒƒå›´
{period}

## æ¦‚è§ˆ
- æ€»è®°å½•æ—¶é•¿: {stats['total_hours']} å°æ—¶
- æ´»è·ƒæ—¶é•¿ï¼ˆéAFKï¼‰: {stats['not_afk_hours']} å°æ—¶

## åº”ç”¨ä½¿ç”¨ TOP 10
{app_list}

## æŒ‰ç±»åˆ«ç»Ÿè®¡
{category_list}
{editor_section}
"""

        # Calculate activity rate
        activity_rate = (
            round(stats["not_afk_hours"] / stats["total_hours"] * 100, 1)
            if stats["total_hours"] > 0
            else 0
        )

        # Get behavior views
        views = stats.get("views", {})
        timeline_view = views.get("timeline", "ï¼ˆæ— æ•°æ®ï¼‰")
        session_view = views.get("sessions", "ï¼ˆæ— æ•°æ®ï¼‰")
        hourly_switches_view = views.get("hourly_switches", "ï¼ˆæ— æ•°æ®ï¼‰")
        website_summary_view = views.get("website_summary", "ï¼ˆæ— æ•°æ®ï¼‰")

        # Build trend section if comparison data is available
        trend_section = ""
        if trend_info:
            trend_section = f"\n{trend_info}\n"

        # Build prompt with behavior views for AI insight discovery
        prompt = f"""ä»¥ä¸‹æ˜¯æˆ‘{period_name}ï¼ˆ{period}ï¼‰çš„ç”µè„‘ä½¿ç”¨è¡Œä¸ºæ•°æ®ï¼š

## åŸºç¡€ä¿¡æ¯
- æ€»è®°å½•æ—¶é•¿: {stats['total_hours']} å°æ—¶
- æ´»è·ƒæ—¶é•¿ï¼ˆéAFKï¼‰: {stats['not_afk_hours']} å°æ—¶
- æ´»è·ƒç‡: {activity_rate}%

## åº”ç”¨ä½¿ç”¨æ—¶é—´çº¿
ï¼ˆå±•ç¤ºåº”ç”¨åˆ‡æ¢çš„æ—¶é—´åºåˆ—ï¼Œå¸¦æŒç»­æ—¶é•¿ï¼‰
{timeline_view}

## è¿ç»­ä½¿ç”¨æ®µè½
ï¼ˆç›¸é‚»åŒåº”ç”¨äº‹ä»¶åˆå¹¶åçš„ä½¿ç”¨æ®µè½ï¼Œè¶…è¿‡10åˆ†é’Ÿçš„ï¼‰
{session_view}

## å„å°æ—¶åˆ‡æ¢é¢‘ç‡
ï¼ˆæ¯å°æ—¶åº”ç”¨åˆ‡æ¢æ¬¡æ•°ï¼Œå¯åæ˜ æ³¨æ„åŠ›ç¢ç‰‡åŒ–ç¨‹åº¦ï¼‰
{hourly_switches_view}

## ç½‘ç«™è®¿é—®æ‘˜è¦
{website_summary_view}

## åº”ç”¨ä½¿ç”¨ç»Ÿè®¡
{app_list}

{trend_section}
---

è¯·åˆ†æä¸Šè¿°æ•°æ®ï¼Œå¸®æˆ‘å‘ç°è¡Œä¸ºæ¨¡å¼å’Œæ•ˆç‡æ´å¯Ÿã€‚

## åˆ†æè¦ç‚¹

1. **æ‰“æ–­æ¨¡å¼**ï¼šæœ‰æ²¡æœ‰æŸä¸ªåº”ç”¨/ç½‘ç«™ç»å¸¸æ‰“æ–­å·¥ä½œæµï¼Ÿä»æ—¶é—´çº¿ä¸­å¯»æ‰¾çº¿ç´¢ã€‚
2. **ä½æ•ˆæ—¶æ®µ**ï¼šå“ªä¸ªæ—¶é—´æ®µåˆ‡æ¢æœ€é¢‘ç¹ï¼Ÿè¿™å¯èƒ½æ˜¯æ•ˆç‡è¾ƒä½çš„æ—¶æ®µã€‚
3. **ä¸“æ³¨æ—¶æ®µ**ï¼šä»è¿ç»­ä½¿ç”¨æ®µè½ä¸­ï¼Œæ‰¾å‡ºèƒ½ä¿æŒè¾ƒé•¿ä¸“æ³¨çš„æ—¶é—´æ®µã€‚
4. **è¶‹åŠ¿å˜åŒ–**ï¼šå¯¹æ¯”å†å²æ•°æ®ï¼Œæœ‰ä»€ä¹ˆæ˜¾è‘—çš„è¿›æ­¥æˆ–é€€æ­¥ï¼Ÿ
5. **æœ‰è¶£å‘ç°**ï¼šä»»ä½•ä½ æ³¨æ„åˆ°çš„æ¨¡å¼ã€è§„å¾‹æˆ–å¼‚å¸¸ã€‚

## è¾“å‡ºæ ¼å¼

### ğŸ“Š æ•´ä½“æ¦‚è§ˆ
ï¼ˆ1-2å¥è¯æ€»ç»“æœ¬å‘¨æœŸçš„æ•´ä½“çŠ¶å†µï¼‰

### â° æ—¶é—´åˆ†é…
ï¼ˆæŒ‡å‡ºæ—¶é—´ä¸»è¦èŠ±åœ¨å“ªäº›åº”ç”¨/ç±»åˆ«ï¼Œå æ¯”æœ€é«˜çš„2-3é¡¹ï¼‰

### ğŸ’¡ å‘ç°ä¸æ´å¯Ÿ
ï¼ˆåŸºäºè¡Œä¸ºæ•°æ®å‘ç°çš„å…·ä½“æ¨¡å¼ï¼Œç”¨è¦ç‚¹åˆ—å‡ºï¼Œè¦å…·ä½“åˆ°æ—¶é—´ç‚¹æˆ–åº”ç”¨ï¼‰

### ğŸ“ˆ è¶‹åŠ¿å˜åŒ–
ï¼ˆå¦‚æœ‰å†å²å¯¹æ¯”æ•°æ®ï¼ŒæŒ‡å‡ºæ˜¾è‘—çš„è¿›æ­¥æˆ–é€€æ­¥ï¼Œæ²¡æœ‰å†å²æ•°æ®åˆ™è·³è¿‡æ­¤èŠ‚ï¼‰

### âœ… æ”¹è¿›å»ºè®®
ï¼ˆ1-2æ¡å…·ä½“å¯è¡Œçš„å»ºè®®ï¼Œé’ˆå¯¹å‘ç°çš„é—®é¢˜ï¼‰
ä¾‹å¦‚å¥½çš„å»ºè®®ï¼š"14:00-15:00 åˆ‡æ¢é¢‘ç¹ï¼Œè€ƒè™‘æŠŠä¼šè®®å®‰æ’åœ¨è¿™ä¸ªæ—¶æ®µ"
ä¾‹å¦‚å·®çš„å»ºè®®ï¼š"å»ºè®®å‡å°‘åˆ‡æ¢æ¬¡æ•°"ï¼ˆå¤ªæ³›æ³›ï¼‰

### ğŸ¯ é”è¯„
ï¼ˆç”¨ä¸€å¥çŠ€åˆ©ã€ç›´æ¥çš„è¯ç‚¹è¯„ä»Šå¤©çš„å·¥ä½œçŠ¶æ€ï¼Œå¯ä»¥æ¯’èˆŒä½†è¦åŸºäºæ•°æ®ï¼Œåƒæœ‹å‹é—´çš„åæ§½ï¼‰
ä¾‹å¦‚ï¼š"èŠ±äº†3å°æ—¶åœ¨æµè§ˆå™¨ä¸Šï¼Œä½ æ˜¯åœ¨å·¥ä½œè¿˜æ˜¯åœ¨ç½‘ä¸Šå†²æµªï¼Ÿ"
ä¾‹å¦‚ï¼š"åˆ‡æ¢äº†200æ¬¡åº”ç”¨ï¼Œä½ çš„æ³¨æ„åŠ›æ¯”é‡‘é±¼è¿˜çŸ­ã€‚"
ä¾‹å¦‚ï¼š"ä»Šå¤©çŠ¶æ€ä¸é”™ï¼Œç»ˆäºåƒä¸ªæ­£ç»æ‰“å·¥äººäº†ã€‚"

æ³¨æ„ï¼š
- åŸºäºæ•°æ®è¯´è¯ï¼Œä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„ä¿¡æ¯
- å»ºè®®è¦å…·ä½“ã€å¯æ‰§è¡Œï¼Œä¸è¦æ³›æ³›è€Œè°ˆ
- é”è¯„è¦æœ‰è¶£ã€ç›´æ¥ï¼Œä½†ä¸è¦äººèº«æ”»å‡»
- ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ é¢å¤–ç« èŠ‚
"""
        return prompt, data_summary

    def analyze(self, prompt: str) -> str:
        """
        Call the AI API to analyze the data and generate a report.

        Args:
            prompt: The analysis prompt to send to the AI.

        Returns:
            The AI-generated analysis report, or an error message if the
            API call fails.
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸ªäººæ•ˆç‡åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„ç”µè„‘ä½¿ç”¨æ•°æ®ï¼Œ"
                        "æä¾›å®¢è§‚ã€æœ‰æ´å¯ŸåŠ›çš„æ•ˆç‡æŠ¥å‘Šã€‚\n\n"
                        "è¦æ±‚ï¼š\n"
                        "- åŸºäºæ•°æ®è¯´è¯ï¼Œä¸è¦ç¼–é€ æˆ–å‡è®¾ä¸å­˜åœ¨çš„ä¿¡æ¯\n"
                        "- è¯­æ°”å‹å¥½ä½†ä¸“ä¸šï¼Œåƒä¸€ä½å…³å¿ƒç”¨æˆ·çš„æ•ˆç‡æ•™ç»ƒ\n"
                        "- å»ºè®®è¦å…·ä½“å¯è¡Œï¼Œä¸è¦æ³›æ³›è€Œè°ˆ\n"
                        "- ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡ºï¼Œç»“æ„æ¸…æ™°"
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
        }

        try:
            resp = requests.post(
                f"{self.api_base}/chat/completions",
                headers=headers,
                json=payload,
                timeout=120,
            )
            resp.raise_for_status()
            result = resp.json()

            # Handle different response formats
            if "choices" in result and result["choices"]:
                choice = result["choices"][0]
                message = choice.get("message", {})

                # Standard OpenAI format
                if "content" in message and message["content"]:
                    return message["content"]

                # Reasoning model format (like o1/DeepSeek) - has reasoning_content
                if "reasoning_content" in message:
                    # For reasoning models, the actual answer should be in 'content'
                    # If content is empty but we have reasoning, return reasoning
                    content = message.get("content") or message.get("reasoning_content")
                    if content:
                        return content

                # Some APIs use 'text' directly
                if "text" in choice:
                    return choice["text"]

            # If we get here, the response format is unexpected
            return f"AI å“åº”æ ¼å¼å¼‚å¸¸: {result}"

        except requests.exceptions.Timeout:
            return "AI è°ƒç”¨è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        except requests.exceptions.RequestException as e:
            return f"AI è°ƒç”¨å¤±è´¥: {e}"
        except (KeyError, IndexError) as e:
            return f"AI å“åº”è§£æå¤±è´¥: {e}"
